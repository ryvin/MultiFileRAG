# Server Configuration
HOST=0.0.0.0
PORT=9621
WORKERS=2

# Settings for document indexing
ENABLE_LLM_CACHE_FOR_EXTRACT=true
SUMMARY_LANGUAGE=English
MAX_PARALLEL_INSERT=2

# LLM Configuration
TIMEOUT=200
TEMPERATURE=0.0
MAX_ASYNC=4
MAX_TOKENS=32768

# Ollama LLM Configuration
LLM_BINDING=ollama
# Available LLM models: llama3, llama3:8b, llama3:70b, mistral, mixtral, phi3, gemma, gemma:2b, codellama, deepseek-r1:32b, etc.
LLM_MODEL=deepseek-r1:32b
LLM_BINDING_HOST=http://localhost:11434

# Ollama Embedding Configuration
EMBEDDING_BINDING=ollama
EMBEDDING_BINDING_HOST=http://localhost:11434
# Available embedding models: nomic-embed-text, bge-m3, bge-small-en-v1.5, etc.
# Note: bge-m3 requires EMBEDDING_DIM=1024
EMBEDDING_MODEL=bge-m3
EMBEDDING_DIM=1024

# Web UI Configuration
WEBUI_TITLE=MultiFileRAG
WEBUI_DESCRIPTION=Process and query PDF, CSV, and image files with LightRAG

# Storage Configuration
LIGHTRAG_KV_STORAGE=JsonKVStorage
LIGHTRAG_VECTOR_STORAGE=NanoVectorDBStorage
LIGHTRAG_GRAPH_STORAGE=NetworkXStorage
LIGHTRAG_DOC_STATUS_STORAGE=JsonDocStatusStorage

# Working Directory
WORKING_DIR=./rag_storage
INPUT_DIR=./inputs
